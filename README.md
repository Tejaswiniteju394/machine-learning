# Machine Learning Repository

This repository contains implementations and notes on various fundamental Machine Learning algorithms and concepts. It is organized by topics such as supervised and unsupervised learning, model evaluation, and ensemble techniques.

## ðŸ“‚ Contents

### 1. Neural Networks
- Introduction to artificial neural networks
- Architecture: input layer, hidden layers, output layer
- Activation functions: ReLU, Sigmoid, Tanh, Softmax
- Training: backpropagation, gradient descent
- Applications: classification, regression, image recognition

### 2. Clustering
- Unsupervised learning method
- Types: K-Means, Hierarchical, DBSCAN
- Evaluation metrics: Silhouette Score, Daviesâ€“Bouldin Index
- Applications: customer segmentation, anomaly detection

### 3. Support Vector Machine (SVM)
- Supervised learning model for classification and regression
- Concepts: hyperplanes, support vectors, margins
- Kernels: Linear, Polynomial, RBF
- Applications: text classification, bioinformatics

### 4. K-Nearest Neighbour (KNN)
- Instance-based learning method
- Classification based on majority vote from k nearest data points
- Distance metrics: Euclidean, Manhattan
- Advantages: simple, no training phase
- Limitations: sensitive to noise and irrelevant features

### 5. Logistic Regression
- Classification algorithm for binary and multi-class outcomes
- Uses sigmoid function to map predictions to probabilities
- Commonly used for spam detection, disease prediction, etc.

### 6. Decision Trees
- Tree-structured model for classification and regression
- Splits data using features to minimize entropy or Gini impurity
- Easy to visualize and interpret
- Risk of overfitting on training data

### 7. Ensemble Methods
- Combines predictions from multiple models to improve accuracy
- Techniques:
  - Bagging (e.g., Random Forest)
  - Boosting (e.g., AdaBoost, Gradient Boosting)
  - Stacking
- Improves robustness and generalization

### 8. Cross Validation
- Technique to evaluate model performance and prevent overfitting
- Types:
  - k-Fold Cross Validation
  - Stratified k-Fold
  - Leave-One-Out (LOO)
- Ensures model stability and better generalization to unseen data
